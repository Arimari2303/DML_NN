{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2 - DML (Debiased Machine Learning)\n",
    "## Julia Implementation\n",
    "\n",
    "**Compatible con Flux v0.16.5**\n",
    "\n",
    "**Todos los métodos de R incluidos**:\n",
    "- ✅ OLS + Logistic Regression\n",
    "- ✅ Lasso\n",
    "- ✅ Random Forest\n",
    "- ✅ Neural Network (con API nueva de Flux 0.16.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0) Setup e imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Packages loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "using DataFrames, CSV, Downloads\n",
    "using Statistics, Random, LinearAlgebra\n",
    "using GLM          # For OLS and Logistic Regression\n",
    "using GLMNet       # For Lasso\n",
    "using DecisionTree # For Random Forest\n",
    "using Flux         # For Neural Networks\n",
    "using Distributions # For Normal distribution (only for p-values)\n",
    "using Printf\n",
    "\n",
    "Random.seed!(12345)\n",
    "println(\"✓ Packages loaded successfully!\")\n",
    "#println(\"✓ Flux version: \", Flux.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Load and Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Final sample: 5099 rows, 17 predictors\n"
     ]
    }
   ],
   "source": [
    "# Download the data\n",
    "url = \"https://raw.githubusercontent.com/CausalAIBook/MetricsMLNotebooks/main/data/penn_jae.dat\"\n",
    "data_path = Downloads.download(url)\n",
    "DT = CSV.read(data_path, DataFrame, delim=' ', ignorerepeated=true)\n",
    "\n",
    "# Normalize column names to lowercase\n",
    "rename!(DT, [Symbol(lowercase(string(n))) => n for n in names(DT)])\n",
    "\n",
    "# Filter tg == 0 or tg == 4\n",
    "DT = DT[in.(DT.tg, Ref([0, 4])), :]\n",
    "\n",
    "# Create treatment variable\n",
    "DT.T4 = Int.(DT.tg .== 4)\n",
    "\n",
    "# Create outcome variable\n",
    "DT.y = log.(DT.inuidur1)\n",
    "\n",
    "# Create dep dummies\n",
    "DT.dep = Int.(DT.dep)\n",
    "DT.dep_0 = Int.(DT.dep .== 0)\n",
    "DT.dep_1 = Int.(DT.dep .== 1)\n",
    "DT.dep_2 = Int.(DT.dep .== 2)\n",
    "\n",
    "# Handle age variables\n",
    "if !hasproperty(DT, :agelt35) && hasproperty(DT, :age)\n",
    "    DT.agelt35 = Int.(DT.age .< 35)\n",
    "    DT.agegt54 = Int.(DT.age .> 54)\n",
    "end\n",
    "\n",
    "# Define X variables\n",
    "x_vars = [:female, :black, :othrace, \n",
    "          :dep_1, :dep_2,\n",
    "          :q2, :q3, :q4, :q5, :q6,\n",
    "          :recall, :agelt35, :agegt54,\n",
    "          :durable, :nondurable, :lusd, :husd]\n",
    "\n",
    "# Select columns and remove missing\n",
    "use_cols = vcat([:y, :T4], x_vars)\n",
    "DT = DT[:, use_cols]\n",
    "DT = dropmissing(DT)\n",
    "\n",
    "# Extract vectors and matrix\n",
    "y = DT.y\n",
    "d = DT.T4\n",
    "X = Matrix{Float64}(DT[:, x_vars])\n",
    "n, p = size(X)\n",
    "\n",
    "println(\"✓ Final sample: $n rows, $p predictors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Utility functions defined\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Calculate Root Mean Squared Error\"\"\"\n",
    "rmse(a::Vector, b::Vector) = sqrt(mean((a .- b).^2))\n",
    "\n",
    "\"\"\"Calculate theta and standard error for PLM\"\"\"\n",
    "function plm_theta_se(y_tilde::Vector, d_tilde::Vector)\n",
    "    theta = sum(d_tilde .* y_tilde) / sum(d_tilde .* d_tilde)\n",
    "    psi = (y_tilde .- d_tilde .* theta) .* d_tilde\n",
    "    se = sqrt(mean(psi.^2) / (length(y_tilde) * mean(d_tilde.^2)^2))\n",
    "    return (theta=theta, se=se)\n",
    "end\n",
    "\n",
    "println(\"✓ Utility functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Learners\n",
    "\n",
    "### 3.1) OLS and Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ OLS and Logistic functions defined\n"
     ]
    }
   ],
   "source": [
    "# --- OLS and Logistic Regression ---\n",
    "function fit_y_ols(X::Matrix, y::Vector)\n",
    "    n_features = size(X, 2)\n",
    "    col_names = [Symbol(\"x$i\") for i in 1:n_features]\n",
    "    df = DataFrame(X, col_names)\n",
    "    df.y = y\n",
    "    formula_str = \"y ~ \" * join(string.(col_names), \" + \")\n",
    "    return lm(eval(Meta.parse(\"@formula($formula_str)\")), df)\n",
    "end\n",
    "\n",
    "function pred_y_ols(fit, X::Matrix)\n",
    "    n_features = size(X, 2)\n",
    "    col_names = [Symbol(\"x$i\") for i in 1:n_features]\n",
    "    df = DataFrame(X, col_names)\n",
    "    return GLM.predict(fit, df)\n",
    "end\n",
    "\n",
    "function fit_d_logit(X::Matrix, d::Vector)\n",
    "    n_features = size(X, 2)\n",
    "    col_names = [Symbol(\"x$i\") for i in 1:n_features]\n",
    "    df = DataFrame(X, col_names)\n",
    "    df.d = d\n",
    "    formula_str = \"d ~ \" * join(string.(col_names), \" + \")\n",
    "    return glm(eval(Meta.parse(\"@formula($formula_str)\")), df, Binomial(), LogitLink())\n",
    "end\n",
    "\n",
    "function pred_d_logit(fit, X::Matrix)\n",
    "    n_features = size(X, 2)\n",
    "    col_names = [Symbol(\"x$i\") for i in 1:n_features]\n",
    "    df = DataFrame(X, col_names)\n",
    "    return GLM.predict(fit, df)\n",
    "end\n",
    "\n",
    "println(\"✓ OLS and Logistic functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2) Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Lasso functions defined\n"
     ]
    }
   ],
   "source": [
    "# --- Lasso ---\n",
    "function fit_y_lasso(X::Matrix, y::Vector)\n",
    "    return glmnetcv(X, y, alpha=1.0)\n",
    "end\n",
    "\n",
    "function pred_y_lasso(fit, X::Matrix)\n",
    "    return vec(GLMNet.predict(fit, X))\n",
    "end\n",
    "\n",
    "function fit_d_lasso(X::Matrix, d::Vector)\n",
    "    return glmnetcv(X, Float64.(d), alpha=1.0)\n",
    "end\n",
    "\n",
    "function pred_d_lasso(fit, X::Matrix)\n",
    "    preds = GLMNet.predict(fit, X)\n",
    "    return clamp.(vec(preds), 0.0, 1.0)\n",
    "end\n",
    "\n",
    "println(\"✓ Lasso functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3) Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Random Forest functions defined\n"
     ]
    }
   ],
   "source": [
    "# --- Random Forest ---\n",
    "function fit_y_rf(X::Matrix, y::Vector)\n",
    "    return build_forest(y, X, \n",
    "                       n_trees=1000,\n",
    "                       max_depth=-1,\n",
    "                       min_samples_leaf=5,\n",
    "                       rng=Random.MersenneTwister(1))\n",
    "end\n",
    "\n",
    "function pred_y_rf(fit, X::Matrix)\n",
    "    return apply_forest(fit, X)\n",
    "end\n",
    "\n",
    "function pred_d_rf(fit, X::Matrix{Float64})\n",
    "    # Para clasificación binaria con etiquetas \"0\" y \"1\"\n",
    "    probs = apply_forest_proba(fit, X, [\"0\", \"1\"])  # n × 2\n",
    "    # columna 2 = probabilidad de clase \"1\"\n",
    "    return vec(probs[:, 2])\n",
    "end\n",
    "\n",
    "\n",
    "function pred_d_rf(fit, X::Matrix)\n",
    "    preds = apply_forest_proba(fit, X, [\"0\", \"1\"])\n",
    "    return preds[:, 2]\n",
    "end\n",
    "\n",
    "println(\"✓ Random Forest functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pred_d_rf (generic function with 2 methods)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Random Forest (compatible con DecisionTree.jl actual) ---\n",
    "# using DecisionTree\n",
    "\n",
    "function fit_y_rf(X::Matrix{Float64}, y::Vector{Float64})\n",
    "    n_features = size(X, 2)\n",
    "    # número de variables por split (típico: sqrt(p))\n",
    "    n_subfeatures       = max(1, round(Int, sqrt(n_features)))\n",
    "    n_trees             = 1000\n",
    "    partial_sampling    = 0.7      # proporción de filas en cada árbol\n",
    "    max_depth           = -1       # sin límite\n",
    "    min_samples_leaf    = 5\n",
    "    min_samples_split   = 2\n",
    "    min_purity_increase = 0.0\n",
    "    rng                 = Random.MersenneTwister(1)\n",
    "\n",
    "    return build_forest(\n",
    "        y, X,\n",
    "        n_subfeatures,\n",
    "        n_trees,\n",
    "        partial_sampling,\n",
    "        max_depth,\n",
    "        min_samples_leaf,\n",
    "        min_samples_split,\n",
    "        min_purity_increase;\n",
    "        rng = rng,\n",
    "    )\n",
    "end\n",
    "\n",
    "function pred_y_rf(fit, X::Matrix{Float64})\n",
    "    return apply_forest(fit, X)\n",
    "end\n",
    "\n",
    "function fit_d_rf(X::Matrix{Float64}, d::Vector)\n",
    "    # clasificación: etiquetas como strings\n",
    "    d_labels = string.(d)\n",
    "\n",
    "    n_features = size(X, 2)\n",
    "    n_subfeatures       = max(1, round(Int, sqrt(n_features)))\n",
    "    n_trees             = 1000\n",
    "    partial_sampling    = 0.7\n",
    "    max_depth           = -1\n",
    "    min_samples_leaf    = 5\n",
    "    min_samples_split   = 2\n",
    "    min_purity_increase = 0.0\n",
    "    rng                 = Random.MersenneTwister(1)\n",
    "\n",
    "    return build_forest(\n",
    "        d_labels, X,\n",
    "        n_subfeatures,\n",
    "        n_trees,\n",
    "        partial_sampling,\n",
    "        max_depth,\n",
    "        min_samples_leaf,\n",
    "        min_samples_split,\n",
    "        min_purity_increase;\n",
    "        rng = rng,\n",
    "    )\n",
    "end\n",
    "\n",
    "function pred_d_rf(fit, X::Matrix{Float64})\n",
    "    # Devuelve matriz n×K con probabilidades por clase.\n",
    "    # Para etiquetas \"0\",\"1\", la columna 2 es P(d=1|X).\n",
    "    probs = apply_forest_proba(fit, X)\n",
    "    return vec(probs[:, 2])\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pred_d_rf (generic function with 3 methods)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using DecisionTree\n",
    "using Random\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 1) Wrapper de compatibilidad para apply_forest_proba (2 argumentos)\n",
    "#    -> lo convertimos internamente en la llamada correcta de 3 args\n",
    "# ------------------------------------------------------------------\n",
    "import DecisionTree: apply_forest_proba, Ensemble\n",
    "\n",
    "function apply_forest_proba(forest::Ensemble{S,T},\n",
    "                            X::AbstractMatrix{S}) where {S<:AbstractFloat, T}\n",
    "    # En este trabajo d es binaria: 0/1 => usamos etiquetas \"0\",\"1\"\n",
    "    return DecisionTree.apply_forest_proba(forest, X, [\"0\", \"1\"])\n",
    "end\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 2) Random Forest para y (regresión)\n",
    "# ------------------------------------------------------------------\n",
    "function fit_y_rf(X::AbstractMatrix, y::AbstractVector)\n",
    "    Xf = Array{Float64}(X)\n",
    "    yf = Array{Float64}(y)\n",
    "\n",
    "    n_subfeatures       = -1      # usar default (sqrt(#features))\n",
    "    n_trees             = 1000\n",
    "    partial_sampling    = 0.7\n",
    "    max_depth           = -1      # sin límite\n",
    "    min_samples_leaf    = 5\n",
    "    min_samples_split   = 2\n",
    "    min_purity_increase = 0.0\n",
    "    seed                = 1\n",
    "\n",
    "    return build_forest(\n",
    "        yf, Xf,\n",
    "        n_subfeatures,\n",
    "        n_trees,\n",
    "        partial_sampling,\n",
    "        max_depth,\n",
    "        min_samples_leaf,\n",
    "        min_samples_split,\n",
    "        min_purity_increase;\n",
    "        rng = seed,\n",
    "    )\n",
    "end\n",
    "\n",
    "function pred_y_rf(fit, X::AbstractMatrix)\n",
    "    Xf = Array{Float64}(X)\n",
    "    return apply_forest(fit, Xf)\n",
    "end\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 3) Random Forest para d (clasificación binaria)\n",
    "# ------------------------------------------------------------------\n",
    "function fit_d_rf(X::AbstractMatrix, d::AbstractVector)\n",
    "    Xf       = Array{Float64}(X)\n",
    "    d_labels = string.(d)         # \"0\",\"1\"\n",
    "\n",
    "    n_subfeatures       = -1\n",
    "    n_trees             = 1000\n",
    "    partial_sampling    = 0.7\n",
    "    max_depth           = -1\n",
    "    min_samples_leaf    = 5\n",
    "    min_samples_split   = 2\n",
    "    min_purity_increase = 0.0\n",
    "    seed                = 1\n",
    "\n",
    "    return build_forest(\n",
    "        d_labels, Xf,\n",
    "        n_subfeatures,\n",
    "        n_trees,\n",
    "        partial_sampling,\n",
    "        max_depth,\n",
    "        min_samples_leaf,\n",
    "        min_samples_split,\n",
    "        min_purity_increase;\n",
    "        rng = seed,\n",
    "    )\n",
    "end\n",
    "\n",
    "function pred_d_rf(fit, X::AbstractMatrix)\n",
    "    Xf = Array{Float64}(X)\n",
    "\n",
    "    # OJO: aquí usamos el wrapper de 2 args que acabamos de definir arriba\n",
    "    probs = apply_forest_proba(fit, Xf)   # n × 2, columnas: \"0\",\"1\"\n",
    "\n",
    "    # Probabilidad de d=1 (columna asociada a etiqueta \"1\")\n",
    "    return vec(probs[:, 2])\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4) Neural Network - ✅ FLUX 0.16.5 API\n",
    "\n",
    "**Compatible con Flux 0.16.5** - Usa la API completamente nueva y moderna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Neural Network functions defined (Flux 0.16.5 API)\n"
     ]
    }
   ],
   "source": [
    "# --- Neural Network - API FLUX 0.16.5 ---\n",
    "function fit_y_nn(X::Matrix, y::Vector; epochs=100, hidden_size=32)\n",
    "    X_t = Float32.(X')\n",
    "    y_t = Float32.(reshape(y, 1, :))\n",
    "    \n",
    "    n_features = size(X, 2)\n",
    "    model = Chain(\n",
    "        Dense(n_features => hidden_size, relu),\n",
    "        Dense(hidden_size => hidden_size, relu),\n",
    "        Dense(hidden_size => 1)\n",
    "    )\n",
    "    \n",
    "    # ✅ Flux 0.16.5: Setup optimizer state\n",
    "    opt_state = Flux.setup(Adam(0.001), model)\n",
    "    \n",
    "    # ✅ Flux 0.16.5: Training loop sin warnings\n",
    "    for epoch in 1:epochs\n",
    "        loss, grads = Flux.withgradient(model) do m\n",
    "            ŷ = m(X_t)\n",
    "            Flux.mse(ŷ, y_t)\n",
    "        end\n",
    "        \n",
    "        Flux.update!(opt_state, model, grads[1])\n",
    "    end\n",
    "    \n",
    "    return model\n",
    "end\n",
    "\n",
    "function pred_y_nn(fit, X::Matrix)\n",
    "    X_t = Float32.(X')\n",
    "    return vec(fit(X_t))\n",
    "end\n",
    "\n",
    "function fit_d_nn(X::Matrix, d::Vector; epochs=100, hidden_size=32)\n",
    "    X_t = Float32.(X')\n",
    "    d_t = Float32.(reshape(d, 1, :))\n",
    "    \n",
    "    n_features = size(X, 2)\n",
    "    model = Chain(\n",
    "        Dense(n_features => hidden_size, relu),\n",
    "        Dense(hidden_size => hidden_size, relu),\n",
    "        Dense(hidden_size => 1, σ)\n",
    "    )\n",
    "    \n",
    "    # ✅ Flux 0.16.5: Setup optimizer state\n",
    "    opt_state = Flux.setup(Adam(0.001), model)\n",
    "    \n",
    "    # ✅ Flux 0.16.5: Training loop\n",
    "    for epoch in 1:epochs\n",
    "        loss, grads = Flux.withgradient(model) do m\n",
    "            ŷ = m(X_t)\n",
    "            Flux.Losses.binarycrossentropy(ŷ, d_t)\n",
    "        end\n",
    "        \n",
    "        Flux.update!(opt_state, model, grads[1])\n",
    "    end\n",
    "    \n",
    "    return model\n",
    "end\n",
    "\n",
    "function pred_d_nn(fit, X::Matrix)\n",
    "    X_t = Float32.(X')\n",
    "    return vec(fit(X_t))\n",
    "end\n",
    "\n",
    "println(\"✓ Neural Network functions defined (Flux 0.16.5 API)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Learner Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Learners dictionary created (4 methods - igual que R)\n"
     ]
    }
   ],
   "source": [
    "learners = Dict(\n",
    "    \"OLS+LOGIT\" => (\n",
    "        ml_y = (fit = fit_y_ols,   pred = pred_y_ols),\n",
    "        ml_d = (fit = fit_d_logit, pred = pred_d_logit)\n",
    "    ),\n",
    "    \"LASSO\" => (\n",
    "        ml_y = (fit = fit_y_lasso, pred = pred_y_lasso),\n",
    "        ml_d = (fit = fit_d_lasso, pred = pred_d_lasso)\n",
    "    ),\n",
    "    \"RF\" => (\n",
    "        ml_y = (fit = fit_y_rf, pred = pred_y_rf),\n",
    "        ml_d = (fit = fit_d_rf, pred = pred_d_rf)\n",
    "    ),\n",
    "    \"NN\" => (\n",
    "        ml_y = (fit = fit_y_nn, pred = pred_y_nn),\n",
    "        ml_d = (fit = fit_d_nn, pred = pred_d_nn)\n",
    "    )\n",
    ")\n",
    "\n",
    "println(\"✓ Learners dictionary created (4 methods - igual que R)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) DML Functions\n",
    "\n",
    "### 5.1) DML with Cross-Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ DML with cross-fitting defined\n"
     ]
    }
   ],
   "source": [
    "function dml_plm(y::Vector, d::Vector, X::Matrix, K::Int;\n",
    "                 ml_y, ml_d, return_nuisance_rmse::Bool=true)\n",
    "    \n",
    "    n = length(y)\n",
    "    indices = shuffle(1:n)\n",
    "    fold_size = div(n, K)\n",
    "    \n",
    "    y_tilde = zeros(n)\n",
    "    d_tilde = zeros(n)\n",
    "    y_pred_all = zeros(n)\n",
    "    d_pred_all = zeros(n)\n",
    "    \n",
    "    for k in 1:K\n",
    "        test_start = (k-1) * fold_size + 1\n",
    "        test_end = k == K ? n : k * fold_size\n",
    "        \n",
    "        test_idx = indices[test_start:test_end]\n",
    "        train_idx = setdiff(indices, test_idx)\n",
    "        \n",
    "        X_train, X_test = X[train_idx, :], X[test_idx, :]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "        d_train, d_test = d[train_idx], d[test_idx]\n",
    "        \n",
    "        # Fit and predict for y\n",
    "        fit_y = ml_y.fit(X_train, y_train)\n",
    "        y_pred = ml_y.pred(fit_y, X_test)\n",
    "        \n",
    "        # Fit and predict for d\n",
    "        fit_d = ml_d.fit(X_train, d_train)\n",
    "        d_pred = ml_d.pred(fit_d, X_test)\n",
    "        \n",
    "        y_tilde[test_idx] = y_test .- y_pred\n",
    "        d_tilde[test_idx] = d_test .- d_pred\n",
    "        \n",
    "        if return_nuisance_rmse\n",
    "            y_pred_all[test_idx] = y_pred\n",
    "            d_pred_all[test_idx] = d_pred\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    est = plm_theta_se(y_tilde, d_tilde)\n",
    "    \n",
    "    if return_nuisance_rmse\n",
    "        rmse_y = rmse(y, y_pred_all)\n",
    "        rmse_d = rmse(Float64.(d), d_pred_all)\n",
    "        return (theta=est.theta, se=est.se, rmse_y=rmse_y, rmse_d=rmse_d)\n",
    "    else\n",
    "        return est\n",
    "    end\n",
    "end\n",
    "\n",
    "println(\"✓ DML with cross-fitting defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2) DML without Cross-Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ DML without cross-fitting defined\n"
     ]
    }
   ],
   "source": [
    "function dml_plm_no_cf(y::Vector, d::Vector, X::Matrix, K::Int;\n",
    "                       ml_y, ml_d, return_nuisance_rmse::Bool=true)\n",
    "    \n",
    "    # Train on full data\n",
    "    fit_y = ml_y.fit(X, y)\n",
    "    fit_d = ml_d.fit(X, d)\n",
    "    \n",
    "    # Predict on full data (in-sample)\n",
    "    y_pred = ml_y.pred(fit_y, X)\n",
    "    d_pred = ml_d.pred(fit_d, X)\n",
    "    \n",
    "    # Residualize\n",
    "    y_tilde = y .- y_pred\n",
    "    d_tilde = d .- d_pred\n",
    "    \n",
    "    est = plm_theta_se(y_tilde, d_tilde)\n",
    "    \n",
    "    if return_nuisance_rmse\n",
    "        rmse_y = rmse(y, y_pred)\n",
    "        rmse_d = rmse(Float64.(d), d_pred)\n",
    "        return (theta=est.theta, se=est.se, rmse_y=rmse_y, rmse_d=rmse_d)\n",
    "    else\n",
    "        return est\n",
    "    end\n",
    "end\n",
    "\n",
    "println(\"✓ DML without cross-fitting defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Run Both Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Execution functions defined\n"
     ]
    }
   ],
   "source": [
    "function run_block(fun, y::Vector, d::Vector, X::Matrix, K::Int, \n",
    "                   learners::Dict)\n",
    "    results = DataFrame(\n",
    "        Method = String[],\n",
    "        theta = Float64[],\n",
    "        se = Float64[],\n",
    "        pval = Float64[],\n",
    "        rmse_y = Float64[],\n",
    "        rmse_d = Float64[]\n",
    "    )\n",
    "    \n",
    "    for (name, ml) in learners\n",
    "        println(\"  Running $name...\")\n",
    "        Random.seed!(42)\n",
    "        \n",
    "        est = fun(y, d, X, K; ml_y=ml.ml_y, ml_d=ml.ml_d)\n",
    "        \n",
    "        pval = 2 * cdf(Normal(0, 1), -abs(est.theta / est.se))\n",
    "        \n",
    "        push!(results, (\n",
    "            Method = name,\n",
    "            theta = est.theta,\n",
    "            se = est.se,\n",
    "            pval = pval,\n",
    "            rmse_y = est.rmse_y,\n",
    "            rmse_d = est.rmse_d\n",
    "        ))\n",
    "    end\n",
    "    \n",
    "    return results\n",
    "end\n",
    "\n",
    "println(\"✓ Execution functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Running DML with Cross-Fitting...\n",
      "======================================================================\n",
      "  Running LASSO..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Running NN...\n",
      "  Running OLS+LOGIT...\n",
      "  Running RF...\n",
      "\n",
      "✓ Cross-fitting completed!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><div style = \"float: left;\"><span>4×7 DataFrame</span></div><div style = \"clear: both;\"></div></div><div class = \"data-frame\" style = \"overflow-x: scroll;\"><table class = \"data-frame\" style = \"margin-bottom: 6px;\"><thead><tr class = \"header\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">Row</th><th style = \"text-align: left;\">Method</th><th style = \"text-align: left;\">theta</th><th style = \"text-align: left;\">se</th><th style = \"text-align: left;\">pval</th><th style = \"text-align: left;\">rmse_y</th><th style = \"text-align: left;\">rmse_d</th><th style = \"text-align: left;\">CrossFitting</th></tr><tr class = \"subheader headerLastRow\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\"></th><th title = \"String\" style = \"text-align: left;\">String</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"String\" style = \"text-align: left;\">String</th></tr></thead><tbody><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">1</td><td style = \"text-align: left;\">LASSO</td><td style = \"text-align: right;\">-0.0706055</td><td style = \"text-align: right;\">0.03534</td><td style = \"text-align: right;\">0.0457281</td><td style = \"text-align: right;\">1.20175</td><td style = \"text-align: right;\">0.475281</td><td style = \"text-align: left;\">Yes</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">2</td><td style = \"text-align: left;\">NN</td><td style = \"text-align: right;\">-0.0831491</td><td style = \"text-align: right;\">0.0370581</td><td style = \"text-align: right;\">0.0248484</td><td style = \"text-align: right;\">1.26961</td><td style = \"text-align: right;\">0.479523</td><td style = \"text-align: left;\">Yes</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">3</td><td style = \"text-align: left;\">OLS+LOGIT</td><td style = \"text-align: right;\">-0.0657776</td><td style = \"text-align: right;\">0.0350882</td><td style = \"text-align: right;\">0.0608426</td><td style = \"text-align: right;\">1.20197</td><td style = \"text-align: right;\">0.478827</td><td style = \"text-align: left;\">Yes</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">4</td><td style = \"text-align: left;\">RF</td><td style = \"text-align: right;\">-0.0227687</td><td style = \"text-align: right;\">0.0331474</td><td style = \"text-align: right;\">0.492151</td><td style = \"text-align: right;\">1.21583</td><td style = \"text-align: right;\">0.514819</td><td style = \"text-align: left;\">Yes</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccccc}\n",
       "\t& Method & theta & se & pval & rmse\\_y & rmse\\_d & CrossFitting\\\\\n",
       "\t\\hline\n",
       "\t& String & Float64 & Float64 & Float64 & Float64 & Float64 & String\\\\\n",
       "\t\\hline\n",
       "\t1 & LASSO & -0.0706055 & 0.03534 & 0.0457281 & 1.20175 & 0.475281 & Yes \\\\\n",
       "\t2 & NN & -0.0831491 & 0.0370581 & 0.0248484 & 1.26961 & 0.479523 & Yes \\\\\n",
       "\t3 & OLS+LOGIT & -0.0657776 & 0.0350882 & 0.0608426 & 1.20197 & 0.478827 & Yes \\\\\n",
       "\t4 & RF & -0.0227687 & 0.0331474 & 0.492151 & 1.21583 & 0.514819 & Yes \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m4×7 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m Method    \u001b[0m\u001b[1m theta      \u001b[0m\u001b[1m se        \u001b[0m\u001b[1m pval      \u001b[0m\u001b[1m rmse_y  \u001b[0m\u001b[1m rmse_d   \u001b[0m\u001b[1m CrossFi\u001b[0m ⋯\n",
       "     │\u001b[90m String    \u001b[0m\u001b[90m Float64    \u001b[0m\u001b[90m Float64   \u001b[0m\u001b[90m Float64   \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64  \u001b[0m\u001b[90m String \u001b[0m ⋯\n",
       "─────┼──────────────────────────────────────────────────────────────────────────\n",
       "   1 │ LASSO      -0.0706055  0.03534    0.0457281  1.20175  0.475281  Yes     ⋯\n",
       "   2 │ NN         -0.0831491  0.0370581  0.0248484  1.26961  0.479523  Yes\n",
       "   3 │ OLS+LOGIT  -0.0657776  0.0350882  0.0608426  1.20197  0.478827  Yes\n",
       "   4 │ RF         -0.0227687  0.0331474  0.492151   1.21583  0.514819  Yes\n",
       "\u001b[36m                                                                1 column omitted\u001b[0m"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "println(\"=\"^70)\n",
    "println(\"Running DML with Cross-Fitting...\")\n",
    "println(\"=\"^70)\n",
    "\n",
    "K = 2\n",
    "tab_cf = run_block(dml_plm, y, d, X, K, learners)\n",
    "tab_cf.CrossFitting .= \"Yes\"\n",
    "\n",
    "println(\"\\n✓ Cross-fitting completed!\")\n",
    "tab_cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Running DML WITHOUT Cross-Fitting...\n",
      "======================================================================\n",
      "  Running LASSO...\n",
      "  Running NN...\n",
      "  Running OLS+LOGIT...\n",
      "  Running RF...\n",
      "\n",
      "✓ No cross-fitting completed!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><div style = \"float: left;\"><span>4×7 DataFrame</span></div><div style = \"clear: both;\"></div></div><div class = \"data-frame\" style = \"overflow-x: scroll;\"><table class = \"data-frame\" style = \"margin-bottom: 6px;\"><thead><tr class = \"header\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">Row</th><th style = \"text-align: left;\">Method</th><th style = \"text-align: left;\">theta</th><th style = \"text-align: left;\">se</th><th style = \"text-align: left;\">pval</th><th style = \"text-align: left;\">rmse_y</th><th style = \"text-align: left;\">rmse_d</th><th style = \"text-align: left;\">CrossFitting</th></tr><tr class = \"subheader headerLastRow\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\"></th><th title = \"String\" style = \"text-align: left;\">String</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"String\" style = \"text-align: left;\">String</th></tr></thead><tbody><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">1</td><td style = \"text-align: left;\">LASSO</td><td style = \"text-align: right;\">-0.0726661</td><td style = \"text-align: right;\">0.0351212</td><td style = \"text-align: right;\">0.0385449</td><td style = \"text-align: right;\">1.19057</td><td style = \"text-align: right;\">0.473694</td><td style = \"text-align: left;\">No</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">2</td><td style = \"text-align: left;\">NN</td><td style = \"text-align: right;\">-0.0876378</td><td style = \"text-align: right;\">0.0368471</td><td style = \"text-align: right;\">0.017387</td><td style = \"text-align: right;\">1.24319</td><td style = \"text-align: right;\">0.472044</td><td style = \"text-align: left;\">No</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">3</td><td style = \"text-align: left;\">OLS+LOGIT</td><td style = \"text-align: right;\">-0.0726457</td><td style = \"text-align: right;\">0.0351153</td><td style = \"text-align: right;\">0.0385672</td><td style = \"text-align: right;\">1.19047</td><td style = \"text-align: right;\">0.473362</td><td style = \"text-align: left;\">No</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">4</td><td style = \"text-align: left;\">RF</td><td style = \"text-align: right;\">-0.0684385</td><td style = \"text-align: right;\">0.0331128</td><td style = \"text-align: right;\">0.0387504</td><td style = \"text-align: right;\">1.13257</td><td style = \"text-align: right;\">0.481151</td><td style = \"text-align: left;\">No</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccccc}\n",
       "\t& Method & theta & se & pval & rmse\\_y & rmse\\_d & CrossFitting\\\\\n",
       "\t\\hline\n",
       "\t& String & Float64 & Float64 & Float64 & Float64 & Float64 & String\\\\\n",
       "\t\\hline\n",
       "\t1 & LASSO & -0.0726661 & 0.0351212 & 0.0385449 & 1.19057 & 0.473694 & No \\\\\n",
       "\t2 & NN & -0.0876378 & 0.0368471 & 0.017387 & 1.24319 & 0.472044 & No \\\\\n",
       "\t3 & OLS+LOGIT & -0.0726457 & 0.0351153 & 0.0385672 & 1.19047 & 0.473362 & No \\\\\n",
       "\t4 & RF & -0.0684385 & 0.0331128 & 0.0387504 & 1.13257 & 0.481151 & No \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m4×7 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m Method    \u001b[0m\u001b[1m theta      \u001b[0m\u001b[1m se        \u001b[0m\u001b[1m pval      \u001b[0m\u001b[1m rmse_y  \u001b[0m\u001b[1m rmse_d   \u001b[0m\u001b[1m CrossFi\u001b[0m ⋯\n",
       "     │\u001b[90m String    \u001b[0m\u001b[90m Float64    \u001b[0m\u001b[90m Float64   \u001b[0m\u001b[90m Float64   \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64  \u001b[0m\u001b[90m String \u001b[0m ⋯\n",
       "─────┼──────────────────────────────────────────────────────────────────────────\n",
       "   1 │ LASSO      -0.0726661  0.0351212  0.0385449  1.19057  0.473694  No      ⋯\n",
       "   2 │ NN         -0.0876378  0.0368471  0.017387   1.24319  0.472044  No\n",
       "   3 │ OLS+LOGIT  -0.0726457  0.0351153  0.0385672  1.19047  0.473362  No\n",
       "   4 │ RF         -0.0684385  0.0331128  0.0387504  1.13257  0.481151  No\n",
       "\u001b[36m                                                                1 column omitted\u001b[0m"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "println(\"=\"^70)\n",
    "println(\"Running DML WITHOUT Cross-Fitting...\")\n",
    "println(\"=\"^70)\n",
    "\n",
    "tab_nocf = run_block(dml_plm_no_cf, y, d, X, K, learners)\n",
    "tab_nocf.CrossFitting .= \"No\"\n",
    "\n",
    "println(\"\\n✓ No cross-fitting completed!\")\n",
    "tab_nocf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ALL RESULTS\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><div style = \"float: left;\"><span>8×7 DataFrame</span></div><div style = \"clear: both;\"></div></div><div class = \"data-frame\" style = \"overflow-x: scroll;\"><table class = \"data-frame\" style = \"margin-bottom: 6px;\"><thead><tr class = \"header\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">Row</th><th style = \"text-align: left;\">Method</th><th style = \"text-align: left;\">theta</th><th style = \"text-align: left;\">se</th><th style = \"text-align: left;\">pval</th><th style = \"text-align: left;\">rmse_y</th><th style = \"text-align: left;\">rmse_d</th><th style = \"text-align: left;\">CrossFitting</th></tr><tr class = \"subheader headerLastRow\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\"></th><th title = \"String\" style = \"text-align: left;\">String</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"String\" style = \"text-align: left;\">String</th></tr></thead><tbody><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">1</td><td style = \"text-align: left;\">LASSO</td><td style = \"text-align: right;\">-0.0726661</td><td style = \"text-align: right;\">0.0351212</td><td style = \"text-align: right;\">0.0385449</td><td style = \"text-align: right;\">1.19057</td><td style = \"text-align: right;\">0.473694</td><td style = \"text-align: left;\">No</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">2</td><td style = \"text-align: left;\">NN</td><td style = \"text-align: right;\">-0.0876378</td><td style = \"text-align: right;\">0.0368471</td><td style = \"text-align: right;\">0.017387</td><td style = \"text-align: right;\">1.24319</td><td style = \"text-align: right;\">0.472044</td><td style = \"text-align: left;\">No</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">3</td><td style = \"text-align: left;\">OLS+LOGIT</td><td style = \"text-align: right;\">-0.0726457</td><td style = \"text-align: right;\">0.0351153</td><td style = \"text-align: right;\">0.0385672</td><td style = \"text-align: right;\">1.19047</td><td style = \"text-align: right;\">0.473362</td><td style = \"text-align: left;\">No</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">4</td><td style = \"text-align: left;\">RF</td><td style = \"text-align: right;\">-0.0684385</td><td style = \"text-align: right;\">0.0331128</td><td style = \"text-align: right;\">0.0387504</td><td style = \"text-align: right;\">1.13257</td><td style = \"text-align: right;\">0.481151</td><td style = \"text-align: left;\">No</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">5</td><td style = \"text-align: left;\">LASSO</td><td style = \"text-align: right;\">-0.0706055</td><td style = \"text-align: right;\">0.03534</td><td style = \"text-align: right;\">0.0457281</td><td style = \"text-align: right;\">1.20175</td><td style = \"text-align: right;\">0.475281</td><td style = \"text-align: left;\">Yes</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">6</td><td style = \"text-align: left;\">NN</td><td style = \"text-align: right;\">-0.0831491</td><td style = \"text-align: right;\">0.0370581</td><td style = \"text-align: right;\">0.0248484</td><td style = \"text-align: right;\">1.26961</td><td style = \"text-align: right;\">0.479523</td><td style = \"text-align: left;\">Yes</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">7</td><td style = \"text-align: left;\">OLS+LOGIT</td><td style = \"text-align: right;\">-0.0657776</td><td style = \"text-align: right;\">0.0350882</td><td style = \"text-align: right;\">0.0608426</td><td style = \"text-align: right;\">1.20197</td><td style = \"text-align: right;\">0.478827</td><td style = \"text-align: left;\">Yes</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">8</td><td style = \"text-align: left;\">RF</td><td style = \"text-align: right;\">-0.0227687</td><td style = \"text-align: right;\">0.0331474</td><td style = \"text-align: right;\">0.492151</td><td style = \"text-align: right;\">1.21583</td><td style = \"text-align: right;\">0.514819</td><td style = \"text-align: left;\">Yes</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccccc}\n",
       "\t& Method & theta & se & pval & rmse\\_y & rmse\\_d & CrossFitting\\\\\n",
       "\t\\hline\n",
       "\t& String & Float64 & Float64 & Float64 & Float64 & Float64 & String\\\\\n",
       "\t\\hline\n",
       "\t1 & LASSO & -0.0726661 & 0.0351212 & 0.0385449 & 1.19057 & 0.473694 & No \\\\\n",
       "\t2 & NN & -0.0876378 & 0.0368471 & 0.017387 & 1.24319 & 0.472044 & No \\\\\n",
       "\t3 & OLS+LOGIT & -0.0726457 & 0.0351153 & 0.0385672 & 1.19047 & 0.473362 & No \\\\\n",
       "\t4 & RF & -0.0684385 & 0.0331128 & 0.0387504 & 1.13257 & 0.481151 & No \\\\\n",
       "\t5 & LASSO & -0.0706055 & 0.03534 & 0.0457281 & 1.20175 & 0.475281 & Yes \\\\\n",
       "\t6 & NN & -0.0831491 & 0.0370581 & 0.0248484 & 1.26961 & 0.479523 & Yes \\\\\n",
       "\t7 & OLS+LOGIT & -0.0657776 & 0.0350882 & 0.0608426 & 1.20197 & 0.478827 & Yes \\\\\n",
       "\t8 & RF & -0.0227687 & 0.0331474 & 0.492151 & 1.21583 & 0.514819 & Yes \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m8×7 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m Method    \u001b[0m\u001b[1m theta      \u001b[0m\u001b[1m se        \u001b[0m\u001b[1m pval      \u001b[0m\u001b[1m rmse_y  \u001b[0m\u001b[1m rmse_d   \u001b[0m\u001b[1m CrossFi\u001b[0m ⋯\n",
       "     │\u001b[90m String    \u001b[0m\u001b[90m Float64    \u001b[0m\u001b[90m Float64   \u001b[0m\u001b[90m Float64   \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64  \u001b[0m\u001b[90m String \u001b[0m ⋯\n",
       "─────┼──────────────────────────────────────────────────────────────────────────\n",
       "   1 │ LASSO      -0.0726661  0.0351212  0.0385449  1.19057  0.473694  No      ⋯\n",
       "   2 │ NN         -0.0876378  0.0368471  0.017387   1.24319  0.472044  No\n",
       "   3 │ OLS+LOGIT  -0.0726457  0.0351153  0.0385672  1.19047  0.473362  No\n",
       "   4 │ RF         -0.0684385  0.0331128  0.0387504  1.13257  0.481151  No\n",
       "   5 │ LASSO      -0.0706055  0.03534    0.0457281  1.20175  0.475281  Yes     ⋯\n",
       "   6 │ NN         -0.0831491  0.0370581  0.0248484  1.26961  0.479523  Yes\n",
       "   7 │ OLS+LOGIT  -0.0657776  0.0350882  0.0608426  1.20197  0.478827  Yes\n",
       "   8 │ RF         -0.0227687  0.0331474  0.492151   1.21583  0.514819  Yes\n",
       "\u001b[36m                                                                1 column omitted\u001b[0m"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine results\n",
    "results_all = vcat(tab_cf, tab_nocf)\n",
    "sort!(results_all, [:CrossFitting, :Method])\n",
    "\n",
    "println(\"=\"^70)\n",
    "println(\"ALL RESULTS\")\n",
    "println(\"=\"^70)\n",
    "results_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) OLS with Controls as Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m `C:\\Users\\ASUS\\.julia\\environments\\v1.11\\Project.toml`\n",
      "  \u001b[90m[3eaba693] \u001b[39m\u001b[92m+ StatsModels v0.7.7\u001b[39m\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `C:\\Users\\ASUS\\.julia\\environments\\v1.11\\Manifest.toml`\n"
     ]
    }
   ],
   "source": [
    "import Pkg; Pkg.add(\"StatsModels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: using StatsModels.formula in module Main conflicts with an existing identifier.\n"
     ]
    }
   ],
   "source": [
    "using StatsBase\n",
    "using GLM\n",
    "using StatsModels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Running OLS with Controls...\n",
      "======================================================================\n",
      "✓ OLS with controls completed!\n"
     ]
    }
   ],
   "source": [
    "println(\"=\"^70)\n",
    "println(\"Running OLS with Controls...\")\n",
    "println(\"=\"^70)\n",
    "\n",
    "# Si quieres seguir teniendo el DataFrame para inspección:\n",
    "df_full = DataFrame(X, x_vars)\n",
    "df_full.y = y\n",
    "df_full.d = d\n",
    "\n",
    "n, p = size(X)\n",
    "\n",
    "# ---------------- OLS: y ~ d + X (intercepto + d + controles) ----------------\n",
    "X_ols = hcat(ones(n), d, X)   # columnas: 1=intercepto, 2=d, 3..=controles\n",
    "\n",
    "ols_full = lm(X_ols, y)       # interfaz matricial de GLM\n",
    "\n",
    "ols_coef_table = GLM.coeftable(ols_full)\n",
    "d_idx = 2                     # segunda columna es d\n",
    "\n",
    "theta_ols_controls = GLM.coef(ols_full)[d_idx]\n",
    "se_ols_controls    = GLM.stderror(ols_full)[d_idx]\n",
    "pval_ols_controls  = ols_coef_table.cols[4][d_idx]\n",
    "\n",
    "y_pred_ols = GLM.predict(ols_full, X_ols)\n",
    "rmse_y_ols = rmse(y, y_pred_ols)\n",
    "\n",
    "# ---------------- LOGIT: d ~ X (intercepto + controles X) ----------------\n",
    "X_logit = hcat(ones(n), X)    # aquí NO incluimos d como regressor\n",
    "\n",
    "logit_d = glm(X_logit, d, Binomial(), LogitLink())\n",
    "d_pred_logit = GLM.predict(logit_d, X_logit)\n",
    "rmse_d_ols = rmse(Float64.(d), d_pred_logit)\n",
    "\n",
    "# ---------------- Agregar fila a results_all ----------------\n",
    "ols_row = DataFrame(\n",
    "    Method       = [\"OLS with controls\"],\n",
    "    theta        = [theta_ols_controls],\n",
    "    se           = [se_ols_controls],\n",
    "    pval         = [pval_ols_controls],\n",
    "    rmse_y       = [rmse_y_ols],\n",
    "    rmse_d       = [rmse_d_ols],\n",
    "    CrossFitting = [\"N/A\"],\n",
    ")\n",
    "\n",
    "results_all = vcat(results_all, ols_row)\n",
    "sort!(results_all, [:CrossFitting, :Method])\n",
    "\n",
    "println(\"✓ OLS with controls completed!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8) Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Model Selection...\n",
      "======================================================================\n",
      "\n",
      "✓ Best model (smallest SE with cross-fitting):\n",
      "  Method: RF\n",
      "  theta=-0.0228, se=0.0331, pval=0.4922\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><div style = \"float: left;\"><span>DataFrameRow (7 columns)</span></div><div style = \"clear: both;\"></div></div><div class = \"data-frame\" style = \"overflow-x: scroll;\"><table class = \"data-frame\" style = \"margin-bottom: 6px;\"><thead><tr class = \"header\"><th class = \"rowLabel\" style = \"font-weight: bold; text-align: right;\">Row</th><th style = \"text-align: left;\">Method</th><th style = \"text-align: left;\">theta</th><th style = \"text-align: left;\">se</th><th style = \"text-align: left;\">pval</th><th style = \"text-align: left;\">rmse_y</th><th style = \"text-align: left;\">rmse_d</th><th style = \"text-align: left;\">CrossFitting</th></tr><tr class = \"subheader headerLastRow\"><th class = \"rowLabel\" style = \"font-weight: bold; text-align: right;\"></th><th title = \"String\" style = \"text-align: left;\">String</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"String\" style = \"text-align: left;\">String</th></tr></thead><tbody><tr><td class = \"rowLabel\" style = \"font-weight: bold; text-align: right;\">1</td><td style = \"text-align: left;\">RF</td><td style = \"text-align: right;\">-0.0227687</td><td style = \"text-align: right;\">0.0331474</td><td style = \"text-align: right;\">0.492151</td><td style = \"text-align: right;\">1.21583</td><td style = \"text-align: right;\">0.514819</td><td style = \"text-align: left;\">Yes</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccccc}\n",
       "\t& Method & theta & se & pval & rmse\\_y & rmse\\_d & CrossFitting\\\\\n",
       "\t\\hline\n",
       "\t& String & Float64 & Float64 & Float64 & Float64 & Float64 & String\\\\\n",
       "\t\\hline\n",
       "\t1 & RF & -0.0227687 & 0.0331474 & 0.492151 & 1.21583 & 0.514819 & Yes \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1mDataFrameRow\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m Method \u001b[0m\u001b[1m theta      \u001b[0m\u001b[1m se        \u001b[0m\u001b[1m pval     \u001b[0m\u001b[1m rmse_y  \u001b[0m\u001b[1m rmse_d   \u001b[0m\u001b[1m CrossFittin\u001b[0m ⋯\n",
       "     │\u001b[90m String \u001b[0m\u001b[90m Float64    \u001b[0m\u001b[90m Float64   \u001b[0m\u001b[90m Float64  \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64  \u001b[0m\u001b[90m String     \u001b[0m ⋯\n",
       "─────┼──────────────────────────────────────────────────────────────────────────\n",
       "   1 │ RF      -0.0227687  0.0331474  0.492151  1.21583  0.514819  Yes         ⋯\n",
       "\u001b[36m                                                                1 column omitted\u001b[0m"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "println(\"=\"^70)\n",
    "println(\"Model Selection...\")\n",
    "println(\"=\"^70)\n",
    "\n",
    "tab_cf_sorted = sort(tab_cf, :se)\n",
    "best_cf = tab_cf_sorted[1, :]\n",
    "\n",
    "println(\"\\n✓ Best model (smallest SE with cross-fitting):\")\n",
    "println(\"  Method: \", best_cf.Method)\n",
    "@printf(\"  theta=%.4f, se=%.4f, pval=%.4g\\n\", \n",
    "        best_cf.theta, best_cf.se, best_cf.pval)\n",
    "\n",
    "best_cf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9) Print Readable Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Table A. DML con cross-fitting \n",
      "----------------------------------------------------------------------\n",
      "\u001b[1m4×7 DataFrame\u001b[0m\n",
      "\u001b[1m Row \u001b[0m│\u001b[1m CrossFitting \u001b[0m\u001b[1m Method    \u001b[0m\u001b[1m theta   \u001b[0m\u001b[1m se      \u001b[0m\u001b[1m pval    \u001b[0m\u001b[1m rmse_y  \u001b[0m\u001b[1m rmse_d  \u001b[0m\n",
      "     │\u001b[90m String       \u001b[0m\u001b[90m String    \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\n",
      "─────┼──────────────────────────────────────────────────────────────────────\n",
      "   1 │ Yes           LASSO      -0.0706   0.0353   0.0457   1.2017   0.4753\n",
      "   2 │ Yes           NN         -0.0831   0.0371   0.0248   1.2696   0.4795\n",
      "   3 │ Yes           OLS+LOGIT  -0.0658   0.0351   0.0608   1.202    0.4788\n",
      "   4 │ Yes           RF         -0.0228   0.0331   0.492    1.2158   0.5148\n",
      "----------------------------------------------------------------------\n",
      "\n",
      " Table B. DML sin cross-fitting \n",
      "----------------------------------------------------------------------\n",
      "\u001b[1m4×7 DataFrame\u001b[0m\n",
      "\u001b[1m Row \u001b[0m│\u001b[1m CrossFitting \u001b[0m\u001b[1m Method    \u001b[0m\u001b[1m theta   \u001b[0m\u001b[1m se      \u001b[0m\u001b[1m pval    \u001b[0m\u001b[1m rmse_y  \u001b[0m\u001b[1m rmse_d  \u001b[0m\n",
      "     │\u001b[90m String       \u001b[0m\u001b[90m String    \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\n",
      "─────┼──────────────────────────────────────────────────────────────────────\n",
      "   1 │ No            LASSO      -0.0727   0.0351   0.0385   1.1906   0.4737\n",
      "   2 │ No            NN         -0.0876   0.0368   0.0174   1.2432   0.472\n",
      "   3 │ No            OLS+LOGIT  -0.0726   0.0351   0.0386   1.1905   0.4734\n",
      "   4 │ No            RF         -0.0684   0.0331   0.0388   1.1326   0.4812\n",
      "----------------------------------------------------------------------\n",
      "\n",
      " Appendix. Todos los modelos (incluye OLS con controles) \n",
      "----------------------------------------------------------------------\n",
      "\u001b[1m9×7 DataFrame\u001b[0m\n",
      "\u001b[1m Row \u001b[0m│\u001b[1m CrossFitting \u001b[0m\u001b[1m Method            \u001b[0m\u001b[1m theta   \u001b[0m\u001b[1m se      \u001b[0m\u001b[1m pval    \u001b[0m\u001b[1m rmse_y  \u001b[0m\u001b[1m rmse_d  \u001b[0m\n",
      "     │\u001b[90m String       \u001b[0m\u001b[90m String            \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\n",
      "─────┼──────────────────────────────────────────────────────────────────────────────\n",
      "   1 │ N/A           OLS with controls  -0.0726   0.0353   0.0397   1.19     0.4734\n",
      "   2 │ No            LASSO              -0.0727   0.0351   0.0385   1.1906   0.4737\n",
      "   3 │ No            NN                 -0.0876   0.0368   0.0174   1.2432   0.472\n",
      "   4 │ No            OLS+LOGIT          -0.0726   0.0351   0.0386   1.1905   0.4734\n",
      "   5 │ No            RF                 -0.0684   0.0331   0.0388   1.1326   0.4812\n",
      "   6 │ Yes           LASSO              -0.0706   0.0353   0.0457   1.2017   0.4753\n",
      "   7 │ Yes           NN                 -0.0831   0.0371   0.0248   1.2696   0.4795\n",
      "   8 │ Yes           OLS+LOGIT          -0.0658   0.0351   0.0608   1.202    0.4788\n",
      "   9 │ Yes           RF                 -0.0228   0.0331   0.492    1.2158   0.5148\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "function print_table(tab::DataFrame, title::String)\n",
    "    println(\"\\n $title \")\n",
    "    println(\"-\"^70)\n",
    "    \n",
    "    tab_display = select(tab, \n",
    "        :CrossFitting, :Method,\n",
    "        :theta => (x -> round.(x, digits=4)) => :theta,\n",
    "        :se => (x -> round.(x, digits=4)) => :se,\n",
    "        :pval => (x -> round.(x, sigdigits=3)) => :pval,\n",
    "        :rmse_y => (x -> round.(x, digits=4)) => :rmse_y,\n",
    "        :rmse_d => (x -> round.(x, digits=4)) => :rmse_d\n",
    "    )\n",
    "    \n",
    "    println(tab_display)\n",
    "    println(\"-\"^70)\n",
    "end\n",
    "\n",
    "print_table(filter(row -> row.CrossFitting == \"Yes\", results_all), \n",
    "            \"Table A. DML con cross-fitting\")\n",
    "\n",
    "print_table(filter(row -> row.CrossFitting == \"No\", results_all), \n",
    "            \"Table B. DML sin cross-fitting\")\n",
    "\n",
    "print_table(results_all, \n",
    "            \"Appendix. Todos los modelos (incluye OLS con controles)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10) Answers\n",
    "\n",
    "### PLM and DML\n",
    "We estimate the partially linear model:\n",
    "$$y = \\theta d + g_0(X) + \\varepsilon, \\quad d = m_0(X) + \\nu$$\n",
    "\n",
    "DML uses cross-fitting to build out-of-sample residuals:\n",
    "$$\\tilde{y} = y - \\hat{g}(X), \\; \\tilde{d} = d - \\hat{m}(X)$$\n",
    "\n",
    "and estimates:\n",
    "$$\\hat{\\theta} = \\frac{\\sum_i \\tilde{d}_i \\tilde{y}_i}{\\sum_i \\tilde{d}_i^2}$$\n",
    "\n",
    "with IF-based standard errors.\n",
    "\n",
    "### Cross-fitting vs no cross-fitting\n",
    "- RMSE for predicting $y$ and $d$ is usually **smaller** without cross-fitting due to in-sample optimism.\n",
    "- Lower RMSE there does **not** mean better causal inference; it reflects **overfitting** of nuisances.\n",
    "- Sin cross-fitting, el sesgo de regularización se filtra al estimando y genera **sesgo** y **inferencias no conservadoras**.\n",
    "\n",
    "### Selected model\n",
    "Choose the CF method with the smallest SE in Table A and report its $\\hat{\\theta}$ as the final effect."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.6",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
