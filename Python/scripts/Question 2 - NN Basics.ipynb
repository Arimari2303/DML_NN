{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "500c10d7-61d1-48fa-8297-c42a6eedd508",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import (\n",
    "    LinearRegression, LogisticRegression,\n",
    "    LassoCV, LogisticRegressionCV\n",
    ")\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.neural_network import MLPRegressor, MLPClassifier\n",
    "from math import erf, sqrt\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b66a40f7-249c-4367-b7a4-bbdf5cae366d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        abdt  tg  inuidur1  inuidur2  female  black  hispanic  othrace  dep  \\\n",
      "0      10824   0        18        18       0      0         0        0    2   \n",
      "1      10635   2         7         3       0      0         0        0    0   \n",
      "2      10551   5        18         6       1      0         0        0    0   \n",
      "3      10824   0         1         1       0      0         0        0    0   \n",
      "4      10747   0        27        27       0      0         0        0    0   \n",
      "...      ...  ..       ...       ...     ...    ...       ...      ...  ...   \n",
      "13908  10831   5        27        27       0      0         0        0    0   \n",
      "13909  10677   2         4         4       1      0         0        0    0   \n",
      "13910  10817   4         4         4       0      0         0        0    0   \n",
      "13911  10691   0        27        27       0      0         0        0    0   \n",
      "13912  10677   5        25        25       0      0         0        0    0   \n",
      "\n",
      "       q1  ...  q5  q6  recall  agelt35  agegt54  durable  nondurable  lusd  \\\n",
      "0       0  ...   1   0       0        0        0        0           0     0   \n",
      "1       0  ...   0   0       0        1        0        0           0     1   \n",
      "2       0  ...   0   0       1        0        1        0           0     0   \n",
      "3       0  ...   1   0       0        0        0        0           0     1   \n",
      "4       0  ...   0   0       0        0        0        0           0     1   \n",
      "...    ..  ...  ..  ..     ...      ...      ...      ...         ...   ...   \n",
      "13908   0  ...   1   0       1        0        1        1           0     0   \n",
      "13909   0  ...   0   0       0        0        1        0           0     1   \n",
      "13910   0  ...   1   0       0        0        1        0           0     0   \n",
      "13911   0  ...   0   0       0        0        1        1           0     1   \n",
      "13912   0  ...   0   0       0        0        1        0           1     0   \n",
      "\n",
      "       husd  muld  \n",
      "0         1     0  \n",
      "1         0     0  \n",
      "2         0     0  \n",
      "3         0     0  \n",
      "4         0     0  \n",
      "...     ...   ...  \n",
      "13908     1     0  \n",
      "13909     0     0  \n",
      "13910     0     0  \n",
      "13911     0     0  \n",
      "13912     1     0  \n",
      "\n",
      "[13913 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "DT = pd.read_csv(\"penn_jae.dat.txt\", sep=r\"\\s+\", header=0)        \n",
    "\n",
    "print(DT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c70939-774b-4897-8af5-72310e4a857f",
   "metadata": {},
   "source": [
    "### Limpiar data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f0f7a066-0a2d-457d-ae85-7d42d7cde94e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Muestra final: 5099 filas, 17 predictores.\n"
     ]
    }
   ],
   "source": [
    "# 1. Normaliza nombres a minúsculas\n",
    "DT = DT.rename(columns=str.lower)\n",
    "\n",
    "# 2. Columnas requeridas\n",
    "req_base = [\"tg\", \"inuidur1\", \"dep\"]\n",
    "req_x_core = [\"female\", \"black\", \"othrace\", \"q2\", \"q3\", \"q4\", \"q5\", \"q6\",\n",
    "              \"recall\", \"durable\", \"nondurable\", \"lusd\", \"husd\"]\n",
    "\n",
    "missing = set(req_base + req_x_core) - set(DT.columns)\n",
    "if missing:\n",
    "    raise ValueError(f\"Faltan columnas: {', '.join(missing)}\")\n",
    "\n",
    "# 3. Manejo de edad\n",
    "has_agelt35 = \"agelt35\" in DT.columns\n",
    "has_agegt54 = \"agegt54\" in DT.columns\n",
    "has_age     = \"age\"     in DT.columns\n",
    "\n",
    "if not (has_agelt35 and has_agegt54):\n",
    "    if has_age:\n",
    "        DT[\"agelt35\"] = (DT[\"age\"] < 35).astype(int)\n",
    "        DT[\"agegt54\"] = (DT[\"age\"] > 54).astype(int)\n",
    "    else:\n",
    "        raise ValueError(\"No existen 'agelt35'/'agegt54' ni 'age' para derivarlas.\")\n",
    "\n",
    "\n",
    "# 4. Filtra tg == 0 o tg == 4\n",
    "DT = DT[DT[\"tg\"].isin([0, 4])].copy()\n",
    "\n",
    "# 5. Tratamiento y outcome\n",
    "DT[\"T4\"] = (DT[\"tg\"] == 4).astype(int)\n",
    "DT[\"y\"]  = np.log(DT[\"inuidur1\"])\n",
    "\n",
    "# 6. Dummies para dep (baseline dep_0)\n",
    "\n",
    "DT[\"dep\"] = DT[\"dep\"].astype(int)\n",
    "DT[\"dep_0\"] = (DT[\"dep\"] == 0).astype(int)\n",
    "DT[\"dep_1\"] = (DT[\"dep\"] == 1).astype(int)\n",
    "DT[\"dep_2\"] = (DT[\"dep\"] == 2).astype(int)\n",
    "\n",
    "# 7. Define X como pide el enunciado\n",
    "\n",
    "x_vars = [\n",
    "    \"female\",\"black\",\"othrace\",\n",
    "    \"dep_1\",\"dep_2\",\n",
    "    \"q2\",\"q3\",\"q4\",\"q5\",\"q6\",\n",
    "    \"recall\",\"agelt35\",\"agegt54\",\n",
    "    \"durable\",\"nondurable\",\"lusd\",\"husd\"\n",
    "]\n",
    "\n",
    "missing_x = set(x_vars) - set(DT.columns)\n",
    "if missing_x:\n",
    "    raise ValueError(f\"Faltan columnas de X: {', '.join(missing_x)}\")\n",
    "\n",
    "# 8. Dataset final\n",
    "use_cols = [\"y\", \"T4\"] + x_vars\n",
    "DT = DT[use_cols].dropna()\n",
    "\n",
    "y = DT[\"y\"].to_numpy()\n",
    "d = DT[\"T4\"].to_numpy()\n",
    "X = DT[x_vars].to_numpy()\n",
    "n = len(DT)\n",
    "\n",
    "print(f\"Muestra final: {n} filas, {X.shape[1]} predictores.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49233db1-50bf-4907-beee-7a25ed1e9ed1",
   "metadata": {},
   "source": [
    "### Utilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "38c74ee9-d1a3-4b40-bc73-ebee39237adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(a, b):\n",
    "    a = np.asarray(a)\n",
    "    b = np.asarray(b)\n",
    "    return np.sqrt(np.mean((a - b)**2))\n",
    "\n",
    "def plm_theta_se(y_tilde, d_tilde):\n",
    "    y_tilde = np.asarray(y_tilde)\n",
    "    d_tilde = np.asarray(d_tilde)\n",
    "\n",
    "    theta = np.sum(d_tilde * y_tilde) / np.sum(d_tilde * d_tilde)\n",
    "\n",
    "    psi = (y_tilde - d_tilde * theta) * d_tilde\n",
    "\n",
    "    se = np.sqrt(np.mean(psi**2) / (len(y_tilde) * (np.mean(d_tilde**2)**2)))\n",
    "\n",
    "    return {\n",
    "        \"theta\": theta,\n",
    "        \"se\": se\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3c7855-e237-4aec-a9b0-d0e5bed0d840",
   "metadata": {},
   "source": [
    "### Learners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6304619-36dd-4a1f-a2b0-646cc4db75f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OLS y LOGIT\n",
    "def fit_y_ols(X, y):\n",
    "    X = np.asarray(X)\n",
    "    y = np.asarray(y)\n",
    "    model = LinearRegression()\n",
    "    model.fit(X, y)\n",
    "    return model\n",
    "\n",
    "def pred_y_ols(fit, X):\n",
    "    X = np.asarray(X)\n",
    "    return fit.predict(X)\n",
    "\n",
    "\n",
    "def fit_d_logit(X, d):\n",
    "    X = np.asarray(X)\n",
    "    d = np.asarray(d)\n",
    "    # equivalente a glm binomial (logit)\n",
    "    model = LogisticRegression(solver=\"lbfgs\", max_iter=1000)\n",
    "    model.fit(X, d)\n",
    "    return model\n",
    "\n",
    "def pred_d_logit(fit, X):\n",
    "    X = np.asarray(X)\n",
    "    # probabilidad P(D=1 | X)\n",
    "    return fit.predict_proba(X)[:, 1]\n",
    "\n",
    "\n",
    "# LASSO (regresión y logit)\n",
    "def fit_y_lasso(X, y):\n",
    "    X = np.asarray(X)\n",
    "    y = np.asarray(y)\n",
    "    # cv.glmnet con family=\"gaussian\", alpha=1\n",
    "    model = LassoCV(cv=5, random_state=0)\n",
    "    model.fit(X, y)\n",
    "    return model\n",
    "def pred_y_lasso(fit, X):\n",
    "    X = np.asarray(X)\n",
    "    return fit.predict(X)\n",
    "def fit_d_lasso(X, d):\n",
    "    X = np.asarray(X)\n",
    "    d = np.asarray(d)\n",
    "    # cv.glmnet con family=\"binomial\", alpha=1\n",
    "    model = LogisticRegressionCV(\n",
    "        penalty=\"l1\",\n",
    "        solver=\"saga\",\n",
    "        cv=5,\n",
    "        max_iter=10000\n",
    "    )\n",
    "    model.fit(X, d)\n",
    "    return model\n",
    "def pred_d_lasso(fit, X):\n",
    "    X = np.asarray(X)\n",
    "    # probabilidad P(D=1 | X)\n",
    "    return fit.predict_proba(X)[:, 1]\n",
    "\n",
    "\n",
    "# Random Forest\n",
    "def fit_y_rf(X, y):\n",
    "    X = np.asarray(X)\n",
    "    y = np.asarray(y)\n",
    "    model = RandomForestRegressor(\n",
    "        n_estimators=1000,\n",
    "        max_features=\"sqrt\",\n",
    "        min_samples_leaf=5,\n",
    "        random_state=1\n",
    "    )\n",
    "    model.fit(X, y)\n",
    "    return model\n",
    "def pred_y_rf(fit, X):\n",
    "    X = np.asarray(X)\n",
    "    return fit.predict(X)\n",
    "def fit_d_rf(X, d):\n",
    "    X = np.asarray(X)\n",
    "    d = np.asarray(d)\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=1000,\n",
    "        max_features=\"sqrt\",\n",
    "        min_samples_leaf=5,\n",
    "        random_state=1\n",
    "    )\n",
    "    model.fit(X, d)\n",
    "    return model\n",
    "def pred_d_rf(fit, X):\n",
    "    X = np.asarray(X)\n",
    "    # probabilidad P(D=1 | X)\n",
    "    proba = fit.predict_proba(X)\n",
    "    return proba[:, 1]\n",
    "\n",
    "\n",
    "# Neural net\n",
    "def fit_y_nn(X, y, size=4, decay=1e-4, maxit=500):\n",
    "    X = np.asarray(X)\n",
    "    y = np.asarray(y)\n",
    "    model = MLPRegressor(\n",
    "        hidden_layer_sizes=(size,),\n",
    "        alpha=decay,\n",
    "        max_iter=maxit,\n",
    "        activation=\"relu\" \n",
    "    )\n",
    "    model.fit(X, y)\n",
    "    return model\n",
    "def pred_y_nn(fit, X):\n",
    "    X = np.asarray(X)\n",
    "    return fit.predict(X)\n",
    "def fit_d_nn(X, d, size=3, decay=1e-4, maxit=500):\n",
    "    X = np.asarray(X)\n",
    "    d = np.asarray(d)\n",
    "    model = MLPClassifier(\n",
    "        hidden_layer_sizes=(size,),\n",
    "        alpha=decay,\n",
    "        max_iter=maxit\n",
    "    )\n",
    "    model.fit(X, d)\n",
    "    return model\n",
    "def pred_d_nn(fit, X):\n",
    "    X = np.asarray(X)\n",
    "    proba = fit.predict_proba(X)\n",
    "    if proba.shape[1] == 2:\n",
    "        return proba[:, 1]\n",
    "    return proba[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12cf905-1796-436d-a164-8c9e6346c1b5",
   "metadata": {},
   "source": [
    "### DML con Cross fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "364a8f5d-6ace-4125-aae8-f587401dddb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dml_plm(  y,  d,  X, K=2,ml_y=None,   ml_d=None,  return_nuisance_rmse=True):\n",
    "    if ml_y is None:\n",
    "        ml_y = {\"fit\": fit_y_lasso, \"pred\": pred_y_lasso}\n",
    "    if ml_d is None:\n",
    "        ml_d = {\"fit\": fit_d_lasso, \"pred\": pred_d_lasso}\n",
    "\n",
    "    y = np.asarray(y).ravel()\n",
    "    d = np.asarray(d).ravel()\n",
    "    X = np.asarray(X)\n",
    "\n",
    "    n = len(y)\n",
    "\n",
    "   \n",
    "    fold_ids = np.tile(np.arange(K), int(np.ceil(n / K)))[:n]\n",
    "    np.random.shuffle(fold_ids)\n",
    "    folds = fold_ids\n",
    "\n",
    "    m_hat = np.full(n, np.nan)\n",
    "    g_hat = np.full(n, np.nan)\n",
    "    rmse_y_folds = []\n",
    "    rmse_d_folds = []\n",
    "\n",
    "    for k in range(K):\n",
    "        I_tr = folds != k\n",
    "        I_te = folds == k\n",
    "\n",
    "        fit_m = ml_y[\"fit\"](X[I_tr, :], y[I_tr])\n",
    "        fit_g = ml_d[\"fit\"](X[I_tr, :], d[I_tr])\n",
    "\n",
    "        m_hat[I_te] = ml_y[\"pred\"](fit_m, X[I_te, :])\n",
    "        g_hat[I_te] = ml_d[\"pred\"](fit_g, X[I_te, :])\n",
    "\n",
    "        if return_nuisance_rmse:\n",
    "            rmse_y_folds.append(rmse(y[I_te], m_hat[I_te]))\n",
    "            rmse_d_folds.append(rmse(d[I_te], g_hat[I_te]))\n",
    "\n",
    "    y_tilde = y - m_hat\n",
    "    d_tilde = d - g_hat\n",
    "\n",
    "    est = plm_theta_se(y_tilde, d_tilde)\n",
    "\n",
    "    out = {\n",
    "        \"theta\": est[\"theta\"],\n",
    "        \"se\": est[\"se\"]\n",
    "    }\n",
    "\n",
    "    if return_nuisance_rmse:\n",
    "        out[\"rmse_y\"] = float(np.mean(rmse_y_folds))\n",
    "        out[\"rmse_d\"] = float(np.mean(rmse_d_folds))\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912a3a2b-5d73-47ed-abd9-6fab7a56ad9f",
   "metadata": {},
   "source": [
    "### DML sin crossfiting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d1d06ab9-c1c0-469d-8db3-03ede59091dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dml_plm_no_cf(y,d,X, K=2, ml_y=None, ml_d=None, return_nuisance_rmse=True):\n",
    " \n",
    "    if ml_y is None:\n",
    "        ml_y = {\"fit\": fit_y_lasso, \"pred\": pred_y_lasso}\n",
    "    if ml_d is None:\n",
    "        ml_d = {\"fit\": fit_d_lasso, \"pred\": pred_d_lasso}\n",
    "\n",
    "    y = np.asarray(y).ravel()\n",
    "    d = np.asarray(d).ravel()\n",
    "    X = np.asarray(X)\n",
    "\n",
    "    n = len(y)\n",
    "\n",
    "    fold_ids = np.tile(np.arange(K), int(np.ceil(n / K)))[:n]\n",
    "    np.random.shuffle(fold_ids)\n",
    "    folds = fold_ids\n",
    "\n",
    "    m_hat = np.full(n, np.nan)\n",
    "    g_hat = np.full(n, np.nan)\n",
    "\n",
    "    rmse_y_folds = []\n",
    "    rmse_d_folds = []\n",
    "\n",
    "    for k in range(K):\n",
    "        I_k = (folds == k)\n",
    "\n",
    "        fit_m = ml_y[\"fit\"](X[I_k, :], y[I_k])\n",
    "        fit_g = ml_d[\"fit\"](X[I_k, :], d[I_k])\n",
    "\n",
    "        m_hat[I_k] = ml_y[\"pred\"](fit_m, X[I_k, :])\n",
    "        g_hat[I_k] = ml_d[\"pred\"](fit_g, X[I_k, :])\n",
    "\n",
    "        if return_nuisance_rmse:\n",
    "            rmse_y_folds.append(rmse(y[I_k], m_hat[I_k]))\n",
    "            rmse_d_folds.append(rmse(d[I_k], g_hat[I_k]))\n",
    "\n",
    "    y_tilde = y - m_hat\n",
    "    d_tilde = d - g_hat\n",
    "\n",
    "    est = plm_theta_se(y_tilde, d_tilde)\n",
    "\n",
    "    out = {\n",
    "        \"theta\": est[\"theta\"],\n",
    "        \"se\": est[\"se\"]\n",
    "    }\n",
    "\n",
    "    if return_nuisance_rmse:\n",
    "        out[\"rmse_y\"] = float(np.mean(rmse_y_folds))\n",
    "        out[\"rmse_d\"] = float(np.mean(rmse_d_folds))\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a7a49d-1d7d-452b-858b-9adc68268a97",
   "metadata": {},
   "source": [
    "### Ejecutar CF y no CF con multiples modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "006d4dd5-d959-4d31-be0e-fd91608d6067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Method     theta        se      pval    rmse_y    rmse_d CrossFitting\n",
      "5      LASSO -0.072562  0.035092  0.038661  1.188601  0.473551           No\n",
      "7         NN -0.070317  0.035075  0.044986  1.189861  0.473895           No\n",
      "4  OLS+LOGIT -0.071796  0.035077  0.040676  1.188244  0.472959           No\n",
      "6         RF -0.071405  0.035112  0.041988  1.136144  0.453549           No\n",
      "1      LASSO -0.077234  0.035205  0.028248  1.197006  0.474995          Yes\n",
      "3         NN -0.075268  0.035470  0.033835  1.206131  0.475127          Yes\n",
      "0  OLS+LOGIT -0.075519  0.035218  0.032005  1.197143  0.474581          Yes\n",
      "2         RF -0.074126  0.035016  0.034269  1.198461  0.477559          Yes\n"
     ]
    }
   ],
   "source": [
    "# Normal CDF para el p-valor\n",
    "def normal_cdf(z):\n",
    "    return 0.5 * (1.0 + erf(z / sqrt(2.0)))\n",
    "\n",
    "# Definición de learners (igual que en R)\n",
    "learners = {\n",
    "    \"OLS+LOGIT\": {\n",
    "        \"ml_y\": {\"fit\": fit_y_ols,   \"pred\": pred_y_ols},\n",
    "        \"ml_d\": {\"fit\": fit_d_logit, \"pred\": pred_d_logit},\n",
    "    },\n",
    "    \"LASSO\": {\n",
    "        \"ml_y\": {\"fit\": fit_y_lasso, \"pred\": pred_y_lasso},\n",
    "        \"ml_d\": {\"fit\": fit_d_lasso, \"pred\": pred_d_lasso},\n",
    "    },\n",
    "    \"RF\": {\n",
    "        \"ml_y\": {\"fit\": fit_y_rf,    \"pred\": pred_y_rf},\n",
    "        \"ml_d\": {\"fit\": fit_d_rf,    \"pred\": pred_d_rf},\n",
    "    },\n",
    "    \"NN\": {\n",
    "        \"ml_y\": {\"fit\": fit_y_nn,    \"pred\": pred_y_nn},\n",
    "        \"ml_d\": {\"fit\": fit_d_nn,    \"pred\": pred_d_nn},\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "def run_block(fun, y, d, X, K, learners):\n",
    "    rows = []\n",
    "\n",
    "    for name, ml in learners.items():\n",
    "        # set.seed(42) en cada iteración, como en R\n",
    "        np.random.seed(42)\n",
    "\n",
    "        est = fun(\n",
    "            y=y,\n",
    "            d=d,\n",
    "            X=X,\n",
    "            K=K,\n",
    "            ml_y=ml[\"ml_y\"],\n",
    "            ml_d=ml[\"ml_d\"],\n",
    "            return_nuisance_rmse=True\n",
    "        )\n",
    "\n",
    "        theta = est[\"theta\"]\n",
    "        se    = est[\"se\"]\n",
    "        z     = theta / se\n",
    "        pval  = 2 * (1 - normal_cdf(abs(z)))\n",
    "\n",
    "        rows.append({\n",
    "            \"Method\": name,\n",
    "            \"theta\": theta,\n",
    "            \"se\": se,\n",
    "            \"pval\": pval,\n",
    "            \"rmse_y\": est[\"rmse_y\"],\n",
    "            \"rmse_d\": est[\"rmse_d\"],\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "# Ejecutar con y, d, X ya definidos\n",
    "K = 2\n",
    "\n",
    "tab_cf = run_block(dml_plm, y, d, X, K, learners)\n",
    "tab_cf[\"CrossFitting\"] = \"Yes\"\n",
    "\n",
    "tab_nocf = run_block(dml_plm_no_cf, y, d, X, K, learners)\n",
    "tab_nocf[\"CrossFitting\"] = \"No\"\n",
    "\n",
    "results_all = pd.concat([tab_cf, tab_nocf], ignore_index=True)\n",
    "results_all = results_all.sort_values([\"CrossFitting\", \"Method\"])\n",
    "\n",
    "print(results_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3633f30-8295-4ba3-addf-b4459ee27cc4",
   "metadata": {},
   "source": [
    "### OLS con controles como benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5cedd052-5334-4fae-bd27-497cdc549444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Method     theta        se      pval    rmse_y    rmse_d  \\\n",
      "8  OLS with controls -0.072576  0.035270  0.039671  1.189979  0.473362   \n",
      "0              LASSO -0.072562  0.035092  0.038661  1.188601  0.473551   \n",
      "1                 NN -0.070317  0.035075  0.044986  1.189861  0.473895   \n",
      "2          OLS+LOGIT -0.071796  0.035077  0.040676  1.188244  0.472959   \n",
      "3                 RF -0.071405  0.035112  0.041988  1.136144  0.453549   \n",
      "4              LASSO -0.077234  0.035205  0.028248  1.197006  0.474995   \n",
      "5                 NN -0.075268  0.035470  0.033835  1.206131  0.475127   \n",
      "6          OLS+LOGIT -0.075519  0.035218  0.032005  1.197143  0.474581   \n",
      "7                 RF -0.074126  0.035016  0.034269  1.198461  0.477559   \n",
      "\n",
      "  CrossFitting  \n",
      "8          N/A  \n",
      "0           No  \n",
      "1           No  \n",
      "2           No  \n",
      "3           No  \n",
      "4          Yes  \n",
      "5          Yes  \n",
      "6          Yes  \n",
      "7          Yes  \n"
     ]
    }
   ],
   "source": [
    "colnames = [\"y\", \"d\"] + [f\"x{i}\" for i in range(X.shape[1])]\n",
    "df_full = pd.DataFrame(np.column_stack([y, d, X]), columns=colnames)\n",
    "formula = \"y ~ d + \" + \" + \".join(df_full.columns[2:])\n",
    "ols_full = smf.ols(formula, data=df_full).fit()\n",
    "\n",
    "theta_ols_controls = ols_full.params[\"d\"]\n",
    "se_ols_controls    = ols_full.bse[\"d\"]\n",
    "pval_ols_controls  = ols_full.pvalues[\"d\"]\n",
    "\n",
    "rmse_y = rmse(df_full[\"y\"], ols_full.predict(df_full))\n",
    "\n",
    "logit_full = smf.glm(\"d ~ \" + \" + \".join(df_full.columns[2:]),\n",
    "                     data=df_full,\n",
    "                     family=sm.families.Binomial()).fit()\n",
    "\n",
    "pred_d = logit_full.predict(df_full)\n",
    "rmse_d = rmse(df_full[\"d\"], pred_d)\n",
    "\n",
    "ols_row = pd.DataFrame([{\n",
    "    \"CrossFitting\": \"N/A\",\n",
    "    \"Method\": \"OLS with controls\",\n",
    "    \"theta\": theta_ols_controls,\n",
    "    \"se\": se_ols_controls,\n",
    "    \"pval\": pval_ols_controls,\n",
    "    \"rmse_y\": rmse_y,\n",
    "    \"rmse_d\": rmse_d\n",
    "}])\n",
    "\n",
    "results_all = pd.concat([results_all, ols_row], ignore_index=True)\n",
    "results_all = results_all.sort_values([\"CrossFitting\", \"Method\"])\n",
    "\n",
    "print(results_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b441f4d-86a1-4265-bb1e-0c1dbbf25fbd",
   "metadata": {},
   "source": [
    "### Seleccion de modelo (CF) y estimacion final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7abad2ae-7c63-4c5e-a4ab-c05b2ef2f6d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method                RF\n",
      "theta          -0.074126\n",
      "se              0.035016\n",
      "pval            0.034269\n",
      "rmse_y          1.198461\n",
      "rmse_d          0.477559\n",
      "CrossFitting         Yes\n",
      "Name: 2, dtype: object\n"
     ]
    }
   ],
   "source": [
    "tab_cf_sorted = tab_cf.sort_values(\"se\")\n",
    "best_cf = tab_cf_sorted.iloc[0]\n",
    "print(best_cf)\n",
    "\n",
    "def run_final(method=None):\n",
    "    if method is None:\n",
    "        method = best_cf[\"Method\"]\n",
    "\n",
    "    ml = learners[method]\n",
    "\n",
    "    out = dml_plm(\n",
    "        y=y,\n",
    "        d=d,\n",
    "        X=X,\n",
    "        K=K,\n",
    "        ml_y=ml[\"ml_y\"],\n",
    "        ml_d=ml[\"ml_d\"],\n",
    "        return_nuisance_rmse=True\n",
    "    )\n",
    "\n",
    "    z = out[\"theta\"] / out[\"se\"]\n",
    "    pval = 2 * (1 - normal_cdf(abs(z)))\n",
    "\n",
    "    print(f\"\\nFinal DML (CF) con {method}\")\n",
    "    print(f\"theta={out['theta']:.4f}, se={out['se']:.4f}, pval={pval:.4g}\")\n",
    "\n",
    "    out[\"pval\"] = pval\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd5b597-bdb7-4168-adfa-951d3504f715",
   "metadata": {},
   "source": [
    "### Resumen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "de05b399-ad55-4fb0-a005-ddce53a88374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Table A. DML con cross-fitting\n",
      "-------------------------------------------------------------\n",
      "  CrossFitting     Method   theta      se    pval  rmse_y  rmse_d\n",
      "0          Yes  OLS+LOGIT -0.0755  0.0352  0.0320  1.1971  0.4746\n",
      "1          Yes      LASSO -0.0772  0.0352  0.0282  1.1970  0.4750\n",
      "2          Yes         RF -0.0741  0.0350  0.0343  1.1985  0.4776\n",
      "3          Yes         NN -0.0753  0.0355  0.0338  1.2061  0.4751\n",
      "\n",
      "Table B. DML sin cross-fitting\n",
      "-------------------------------------------------------------\n",
      "  CrossFitting     Method   theta      se    pval  rmse_y  rmse_d\n",
      "0           No  OLS+LOGIT -0.0718  0.0351  0.0407  1.1882  0.4730\n",
      "1           No      LASSO -0.0726  0.0351  0.0387  1.1886  0.4736\n",
      "2           No         RF -0.0714  0.0351  0.0420  1.1361  0.4535\n",
      "3           No         NN -0.0703  0.0351  0.0450  1.1899  0.4739\n",
      "\n",
      "Appendix. Todos los modelos (incluye OLS con controles)\n",
      "-------------------------------------------------------------\n",
      "  CrossFitting             Method   theta      se    pval  rmse_y  rmse_d\n",
      "8          N/A  OLS with controls -0.0726  0.0353  0.0397  1.1900  0.4734\n",
      "0           No              LASSO -0.0726  0.0351  0.0387  1.1886  0.4736\n",
      "1           No                 NN -0.0703  0.0351  0.0450  1.1899  0.4739\n",
      "2           No          OLS+LOGIT -0.0718  0.0351  0.0407  1.1882  0.4730\n",
      "3           No                 RF -0.0714  0.0351  0.0420  1.1361  0.4535\n",
      "4          Yes              LASSO -0.0772  0.0352  0.0282  1.1970  0.4750\n",
      "5          Yes                 NN -0.0753  0.0355  0.0338  1.2061  0.4751\n",
      "6          Yes          OLS+LOGIT -0.0755  0.0352  0.0320  1.1971  0.4746\n",
      "7          Yes                 RF -0.0741  0.0350  0.0343  1.1985  0.4776\n"
     ]
    }
   ],
   "source": [
    "def print_table(TAB, title=\"Resultados\"):\n",
    "    print(f\"\\n{title}\")\n",
    "    print(\"-------------------------------------------------------------\")\n",
    "\n",
    "    df_print = TAB.copy()\n",
    "\n",
    "    df_print[\"theta\"]  = df_print[\"theta\"].round(4)\n",
    "    df_print[\"se\"]     = df_print[\"se\"].round(4)\n",
    "    df_print[\"pval\"]   = df_print[\"pval\"].apply(lambda x: float(f\"{x:.3g}\"))\n",
    "    df_print[\"rmse_y\"] = df_print[\"rmse_y\"].round(4)\n",
    "    df_print[\"rmse_d\"] = df_print[\"rmse_d\"].round(4)\n",
    "\n",
    "    cols = [\"CrossFitting\", \"Method\", \"theta\", \"se\", \"pval\", \"rmse_y\", \"rmse_d\"]\n",
    "    print(df_print[cols])\n",
    "\n",
    "print_table(tab_cf,   \"Table A. DML con cross-fitting\")\n",
    "print_table(tab_nocf, \"Table B. DML sin cross-fitting\")\n",
    "print_table(results_all, \"Appendix. Todos los modelos (incluye OLS con controles)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0f9ece-2c28-4f9e-89bd-b9e61cfda2da",
   "metadata": {},
   "source": [
    "# 10) Respuestas en Markdown\n",
    "# Answers\n",
    "\n",
    "## PLM and DML\n",
    "We estimate the partially linear model\n",
    "$ y = \\\\theta d + g_0(X) + \\\\varepsilon, \\\\quad d = m_0(X) + \\\\nu.$\n",
    "DML uses cross-fitting to build out-of-sample residuals\n",
    "$\\\\tilde y = y - \\\\hat g(X),\\\\; \\\\tilde d = d - \\\\hat m(X)$\n",
    "and\n",
    "$\\\\hat\\\\theta = \\\\frac{\\\\sum_i \\\\tilde d_i\\\\tilde y_i}{\\\\sum_i \\\\tilde d_i^2}$,\n",
    "with IF-based standard errors.\n",
    "\n",
    "## Cross-fitting vs no cross-fitting\n",
    "- RMSE for predicting $y$ and $d$ is usually **smaller** without cross-fitting due to in-sample optimism.\n",
    "- Lower RMSE there does **not** mean better causal inference; it reflects **overfitting** of nuisances.\n",
    "- Sin cross-fitting, el sesgo de regularización se filtra al estimando y genera **sesgo** y **inferencias no conservadoras**.\n",
    "\n",
    "## Selected model\n",
    "Choose the CF method with the smallest SE in Table A and report its $\\\\hat\\\\theta$ as the final effect.\n",
    "\")\n",
    "### RF -0.0741  0.0350  0.0343  1.1985  0.4776\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
